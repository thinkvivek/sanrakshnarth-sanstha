import cx_Oracle
import multiprocessing as mp

# ===== CONFIG =====
SOURCE_DSN = "host1:1521/service1"
SOURCE_USER = "user1"
SOURCE_PASS = "pass1"

TARGET_DSN = "host2:1521/service2"
TARGET_USER = "user2"
TARGET_PASS = "pass2"

NUM_WORKERS = 8
BATCH_SIZE = 50000

# ===== WORKER FUNCTION =====
def transfer_chunk(chunk_id, query, num_chunks):
    src_conn = cx_Oracle.connect(SOURCE_USER, SOURCE_PASS, SOURCE_DSN)
    tgt_conn = cx_Oracle.connect(TARGET_USER, TARGET_PASS, TARGET_DSN)

    src_cur = src_conn.cursor()
    tgt_cur = tgt_conn.cursor()

    src_cur.arraysize = BATCH_SIZE
    tgt_cur.arraysize = BATCH_SIZE

    wrapped_query = f"""
    SELECT * FROM (
        SELECT t.*, ROWID r_id FROM ({query}) t
    ) q
    WHERE MOD(ASCII(SUBSTR(ROWIDTOCHAR(q.r_id), -1, 1)), {num_chunks}) = {chunk_id}
    """

    src_cur.execute(wrapped_query)

    cols = [d[0] for d in src_cur.description]
    placeholders = ", ".join([":" + str(i+1) for i in range(len(cols))])
    insert_sql = f"INSERT /*+ APPEND */ INTO target_table ({', '.join(cols)}) VALUES ({placeholders})"

    batch = []
    for row in src_cur:
        batch.append(row)
        if len(batch) >= BATCH_SIZE:
            tgt_cur.executemany(insert_sql, batch)
            tgt_conn.commit()
            batch.clear()

    if batch:
        tgt_cur.executemany(insert_sql, batch)
        tgt_conn.commit()

    src_cur.close()
    tgt_cur.close()
    src_conn.close()
    tgt_conn.close()

# ===== MAIN =====
if __name__ == "__main__":
    user_sql = open("query.sql").read().strip()

    with mp.Pool(NUM_WORKERS) as pool:
        pool.starmap(transfer_chunk, [(i, user_sql, NUM_WORKERS) for i in range(NUM_WORKERS)])

    print("âœ… Data transfer completed!")
